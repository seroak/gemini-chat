# Gemini API Integration

## Basic Usage

```typescript
import { GoogleGenAI } from "@google/genai";

const client = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });

// Simple response
const result = await client.models.generateContent({
  model: "gemini-2.0-flash",
  contents: [{ role: 'user', parts: [{ text: "Hello" }] }],
});
const response = result.response.text();

// Streaming response
const resultStream = await client.models.generateContentStream({
  model: "gemini-2.0-flash",
  contents: [{ role: 'user', parts: [{ text: "Hello" }] }],
});
for await (const chunk of resultStream.stream) {
  const chunkText = chunk.text();
  // Send to client via WebSocket
}
```

## Multi-turn Conversation

The new SDK uses a stateless approach where you pass the full conversation history in the `contents` array.

```typescript
const history = [
  { role: "user", parts: [{ text: "Hello" }] },
  { role: "model", parts: [{ text: "Hello! How can I help you?" }] },
];

const newPrompt = "Tell me about TypeScript";

const result = await client.models.generateContentStream({
  model: "gemini-2.0-flash",
  contents: [
    ...history,
    { role: "user", parts: [{ text: newPrompt }] }
  ],
});
```

## Best Practices

- **API key security**: Manage via env vars; never expose to client.
- **Rate limiting**: Limit API call frequency (e.g., 60 calls/minute).
- **Error handling**: Handle API errors properly (quota exceeded, network errors, etc.).
- **Prompt optimization**: Avoid unnecessarily long prompts (affects cost and speed).
- Optimize Gemini API calls: prevent unnecessary requests, maintain appropriate prompt length.
